{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from cleverhans.attacks import MomentumIterativeMethod\n",
    "from cleverhans.attacks import Model\n",
    "from PIL import Image\n",
    "slim = tf.contrib.slim\n",
    "# tf.flags.DEFINE_string('f','kernel', '')\n",
    "tf.flags.DEFINE_string(\n",
    "    'checkpoint_path', '../official_data/model/inception_v1/inception_v1.ckpt', 'Path to checkpoint for inception network.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'input_dir', '../official_data/dev_data/', 'Input directory with images.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'output_dir', '', 'Output directory with images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_width', 224, 'Width of each input images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_height', 224, 'Height of each input images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'batch_size', 110, 'How many images process at one time.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'num_classes', 110, 'Number of Classes')\n",
    "FLAGS = tf.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "# from IJCAI19.module.utils import * \n",
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    labels = np.zeros(batch_shape[0], dtype=np.int32)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    with open(os.path.join(input_dir, 'dev.csv')) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            filepath = os.path.join(input_dir, row['filename'])\n",
    "            with open(filepath, 'rb') as f:\n",
    "                raw_image = imread(f, mode='RGB').astype(np.float)\n",
    "                image = imresize(raw_image, [FLAGS.image_height, FLAGS.image_width]) / 255.0\n",
    "            # Images for inception classifier are normalized to be in [-1, 1] interval.\n",
    "            images[idx, :, :, :] = image * 2.0 - 1.0\n",
    "            labels[idx] = int(row['targetedLabel'])\n",
    "            filenames.append(os.path.basename(filepath))\n",
    "            idx += 1\n",
    "            if idx == batch_size:\n",
    "                yield filenames, images, labels\n",
    "                filenames = []\n",
    "                images = np.zeros(batch_shape)\n",
    "                labels = np.zeros(batch_shape[0], dtype=np.int32)\n",
    "                idx = 0\n",
    "        if idx > 0:\n",
    "            yield filenames, images, labels\n",
    "\n",
    "\n",
    "def save_images(images, filenames, output_dir):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        # Images for inception classifier are normalized to be in [-1, 1] interval,\n",
    "        # so rescale them back to [0, 1].\n",
    "        with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "            img = (((images[i, :, :, :] + 1.0) * 0.5) * 255.0).astype(np.uint8)\n",
    "            # resize back to [299, 299]\n",
    "            r_img = imresize(img, [299, 299])\n",
    "            Image.fromarray(r_img).save(f, format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InceptionModel(Model):\n",
    "    \"\"\"Model class for CleverHans library.\"\"\"\n",
    "    def __init__(self, x_input, nb_classes):\n",
    "        super(InceptionModel, self).__init__(nb_classes=nb_classes,\n",
    "                                             needs_dummy_fprop=True)\n",
    "        self.built = False\n",
    "        self.model_endpoints = None\n",
    "        with slim.arg_scope(inception.inception_v1_arg_scope()):\n",
    "            _, self.model_endpoints = inception.inception_v1(\n",
    "                x_input, num_classes=self.nb_classes, is_training=False,\n",
    "                reuse=False)\n",
    "\n",
    "    def __call__(self, x_input, return_logits=False):\n",
    "        \"\"\"Constructs model and return probabilities for given input.\"\"\"\n",
    "        reuse = True if self.built else None\n",
    "#         with slim.arg_scope(inception.inception_v1_arg_scope()):\n",
    "#             _, end_points = inception.inception_v1(\n",
    "#                 x_input, num_classes=self.nb_classes, is_training=False,\n",
    "#                 reuse=reuse)\n",
    "        end_points = self.model_endpoints\n",
    "        self.built = True\n",
    "        self.logits = end_points['Logits']\n",
    "        # Strip off the extra reshape op at the output\n",
    "        self.probs = end_points['Predictions'].op.inputs[0]\n",
    "        if return_logits:\n",
    "            return self.logits\n",
    "        else:\n",
    "            return self.probs\n",
    "\n",
    "    def get_logits(self, x_input):\n",
    "        return self(x_input, return_logits=True)\n",
    "\n",
    "    def get_probs(self, x_input):\n",
    "        return self(x_input)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    \"\"\"Run the sample attack\"\"\"\n",
    "    batch_shape = [FLAGS.batch_size, FLAGS.image_height, FLAGS.image_width, 3]\n",
    "    nb_classes = FLAGS.num_classes\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        # Prepare graph\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "        target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n",
    "        one_hot_target_class = tf.one_hot(target_class_input, nb_classes)\n",
    "        # Run computation\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "            model = InceptionModel(x_input, nb_classes)\n",
    "            mim = MomentumIterativeMethod(model, sess=sess)\n",
    "            attack_params = {\"eps\": 32.0 / 255.0, \"eps_iter\": 0.01, \"clip_min\": -1.0, \"clip_max\": 1.0, \\\n",
    "                             \"nb_iter\": 2, \"decay_factor\": 1.0, \"y_target\": one_hot_target_class}\n",
    "#             x_adv = mim.generate(x_input, **attack_params)\n",
    "#             saver = tf.train.Saver(slim.get_model_variables())\n",
    "#             saver.restore(sess, FLAGS.checkpoint_path)\n",
    "#             for filenames, images, tlabels in load_images(FLAGS.input_dir, batch_shape):\n",
    "#                 adv_images = sess.run(x_adv,\n",
    "#                                       feed_dict={x_input: images, target_class_input: tlabels})\n",
    "#                 save_images(adv_images, filenames, FLAGS.output_dir)\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from cleverhans.compat import reduce_sum, reduce_mean, softmax_cross_entropy_with_logits\n",
    "from IJCAI19.module.gs_mim import GradSmoothMomentumIterativeMethod\n",
    "batch_shape = [None, FLAGS.image_height, FLAGS.image_width, 3]\n",
    "nb_classes = FLAGS.num_classes\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # Prepare graph\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "    target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n",
    "    one_hot_target_class = tf.one_hot(target_class_input, nb_classes)\n",
    "    # Run computation\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        model = InceptionModel(x_input, nb_classes)\n",
    "        mim = GradSmoothMomentumIterativeMethod(model, sess=sess)\n",
    "        attack_params = {\"eps\": 32.0 / 255.0, \"eps_iter\": 0.01, \"clip_min\": -1.0, \"clip_max\": 1.0, \\\n",
    "                         \"nb_iter\": 2, \"decay_factor\": 1.0, \"y_target\": one_hot_target_class}\n",
    "#         x_adv = mim.generate(x_input, **attack_params)\n",
    "#         saver = tf.train.Saver(slim.get_model_variables())\n",
    "#         saver.restore(sess, FLAGS.checkpoint_path)\n",
    "#         for filenames, images, tlabels in load_images(FLAGS.input_dir, batch_shape):\n",
    "#             adv_images = sess.run(x_adv,\n",
    "#                                   feed_dict={x_input: images, target_class_input: tlabels})\n",
    "#             save_images(adv_images, filenames, FLAGS.output_dir)\n",
    "        def cond(i, _, __):\n",
    "          return tf.less(i, 2)\n",
    "        def body(i, ax, m):\n",
    "            y =target_class_input\n",
    "            logits = model.get_logits(ax)\n",
    "            loss = logits\n",
    "#             loss = softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            grad, = tf.gradients(loss, ax)\n",
    "            print(grad)\n",
    "            return i + 1, ax, m\n",
    "        adv_x = x_input\n",
    "        _, adv_x, _ = tf.while_loop(\n",
    "            cond, body, (tf.zeros([]), x_input, 1), back_prop=True,\n",
    "            maximum_iterations=2)\n",
    "\n",
    "#         y =target_class_input\n",
    "#         logits = model.get_logits(x_input)\n",
    "#         loss = softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "#         grad, = tf.gradients(loss, x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'while/Exit_2:0' shape=(?, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
